{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch_geometric\n",
    "from my_functions import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import precision_score, roc_curve, auc\n",
    "from torch.optim import Adam\n",
    "from Classifier import HypergraphNet\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"PyTorch GPU disponibile:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    print(\"GPU utilizzata:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Torch-geometric version:\", torch_geometric.__version__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import dell'ipergrafo costruito per la Network 1: in-silinco",
   "id": "b9b77ba1bde820cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "script_dir = Path(__file__).parent\n",
    "json_filePC = script_dir / \"Net1_PC.json\"\n",
    "input_file = script_dir / \"Dati\" / \"training data\" / \"Network 1 - in silico\" / \"net1_expression_data.tsv\"\n",
    "\n",
    "expression_data, gene_names = read_expression_data(input_file)"
   ],
   "id": "6ef0478d4a531d6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creazione sotto-ipegrafi",
   "id": "d1d6e0cfb66f66e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "threshold = \"0.8\"\n",
    "dataset_positiviPC = create_subgraph_data(json_filePC, expression_data, gene_names, threshold)\n",
    "\n",
    "print(f'Il numero di sotto-grafi PC positivi Ã¨: {len(dataset_positiviPC)}\\n')\n",
    "for x in range(20, 25):\n",
    "    print(dataset_positiviPC[x])"
   ],
   "id": "b6f3968e68cc6123",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hyperedges, unique_genes = load_hypergraph(json_filePC, threshold)\n",
    "dataset_negativiPC = generate_negative_subgraphs(hyperedges, expression_data, gene_names, num_neg_samples=len(dataset_positiviPC))\n",
    "\n",
    "print(f'Il numero di sotto-grafi negativi Ã¨: {len(dataset_negativiPC)}\\n')\n",
    "\n",
    "for x in range(0, 5):\n",
    "    print(dataset_negativiPC[x])"
   ],
   "id": "1967616b6ac9e8ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "K-FOLD CROSS VALIDATION",
   "id": "163a1808572c2497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_with_early_stopping(model, train_loader, optimizer, criterion, epochs=100, patience=30):\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out, data.y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            counter = 0  # Reset se la loss migliora\n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter >= patience:\n",
    "            print(\"ðŸ”´ stop\")\n",
    "            break"
   ],
   "id": "642d265fdb38f099",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Parametri della cross-validation\n",
    "k_folds = 5  # Numero di fold per la K-Fold Cross Validation\n",
    "batch_size = 32\n",
    "hidden_channels = 64\n",
    "out_channels = 1  # binaria\n",
    "criterion = torch.nn.BCELoss()  # Loss per classificazione binaria\n",
    "\n",
    "datasetPC = dataset_positiviPC + dataset_negativiPC\n",
    "# Creazione delle etichette per la stratificazione\n",
    "labels = np.array([data.y.item() for data in datasetPC])\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ],
   "id": "3e20842ce29d1152",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = {\"accuracy\": [], \"precision\": [], \"auc\": []}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(datasetPC, labels)):\n",
    "    print(f\"Fold {fold+1}/{k_folds}\")\n",
    "    \n",
    "    # Creazione dei sottoinsiemi\n",
    "    train_data = [datasetPC[i] for i in train_idx]\n",
    "    test_data = [datasetPC[i] for i in test_idx]\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Modello\n",
    "    in_channels = train_data[0].x.shape[1]  # Numero di feature per nodo\n",
    "    model = HypergraphNet(in_channels, hidden_channels, out_channels)\n",
    "    optimizer = Adam(model.parameters(), lr=0.0005, weight_decay=5e-4)\n",
    "    \n",
    "    # Training\n",
    "    train_with_early_stopping(model, train_loader, optimizer, criterion, epochs=100, patience=30)\n",
    "    \n",
    "    # Testing\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            probs = out.squeeze().cpu().numpy()  # ProbabilitÃ  previste\n",
    "            preds = (probs > 0.5).astype(int)  # Predizioni binarie\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "\n",
    "    # metriche\n",
    "    accuracy = sum([p == l for p, l in zip(all_preds, all_labels)]) / len(all_labels)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"Fold {fold+1} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    metrics[\"accuracy\"].append(accuracy)\n",
    "    metrics[\"precision\"].append(precision)\n",
    "    metrics[\"auc\"].append(roc_auc)"
   ],
   "id": "894d52c6f8051fdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# risultati finali\n",
    "print(\"\\n=== Risultati Finali ===\")\n",
    "print(f\"Accuracy: {np.mean(metrics['accuracy']):.4f} Â± {np.std(metrics['accuracy']):.4f}\")\n",
    "print(f\"Precision: {np.mean(metrics['precision']):.4f} Â± {np.std(metrics['precision']):.4f}\")\n",
    "print(f\"AUC-ROC: {np.mean(metrics['auc']):.4f} Â± {np.std(metrics['auc']):.4f}\")"
   ],
   "id": "98710f36e189b8ce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
